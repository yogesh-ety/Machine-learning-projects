{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Classification Algorithms (BPNN & SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Back Propogation Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Program 1 - Implementing BPNN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### AIM\n",
    "To implement Back Propogation Neural Network from scratch in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ALGORITHM\n",
    "##### Forward propogation\n",
    "###### Single input\n",
    "$$\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\newcommand{\\matrix}[1]{\\begin{bmatrix}{#1}\\end{bmatrix}}\n",
    "\\begin{align*}\n",
    "\\vect{o}_{-1} &= \\vect{x}_i\\\\\n",
    "\\vect{o}_k &= \\vect{\\phi}_k\\left(\n",
    "\\vect{W}_k \n",
    "\\matrix{ 1 \\\\ \\vect{o}_{k-1}}\n",
    "\\right) &\\text{for }k = 0,..,n-1\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Batch input\n",
    "$$\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\begin{align*}\n",
    "\\vect{O}_{-1} &= \\vect{X}^T\\\\\n",
    "\\vect{O}_k &= \\vect{\\phi}_k\\left(\n",
    "\\vect{W}_k^T \n",
    "\\matrix{ \\vect{1} \\\\ \\vect{O}_{k-1}}\n",
    "\\right) &\\text{for }k = 0,..,n-1\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error\n",
    "###### Single Input\n",
    "$$\n",
    "E = \\frac{1}{2}||\\vect{o}_{n-1}-\\vect{t}||_2\n",
    "$$\n",
    "###### Batch Input\n",
    "$$\n",
    "E = \\frac{1}{2m} \\sum_{i=1}^{m} ||\\vect{o}^{(i)}_{n-1}-\\vect{t}||_2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backward Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Single input\n",
    "$$\n",
    "\\newcommand{\\diff}[2]{\\frac{\\mathrm{d}{#1}}{\\mathrm{d}{#2}}}\n",
    "\\begin{align}\n",
    "\\vect{\\delta}_{k} &= \\diff{E}{\\vect{o}_{k}}\\circ \\vect{\\phi}'(\\text{net}_{k} )\\\\\n",
    "\\diff{E}{\\vect{o}_{k}} &= \\begin{cases}\n",
    "(\\vect{o}_{n-1}-\\vect{t}) & k=n-1\\\\\n",
    "\\vect{W}^T_{k+1}\\vect{\\delta}_{k+1} & k = n-2,...,-1 \\\\\n",
    "\\end{cases}\\\\\n",
    "\\vect{\\phi}'(\\text{net}_{k}) &= \\vect{o}_k \\circ (\\vect{1}-\\vect{o}_k)  \\text{ for }   k = n-1,...,0 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Batch input\n",
    "$$\n",
    "\\newcommand{\\diff}[2]{\\frac{\\mathrm{d}{#1}}{\\mathrm{d}{#2}}}\n",
    "\\begin{align}\n",
    "\\vect{\\Delta}_{k} &= \\diff{E}{\\vect{O}_{k}}\\circ \\vect{\\phi}'(\\text{net}_{k} )\\\\\n",
    "\\diff{E}{\\vect{O}_{k}} &= \\begin{cases}\n",
    "(\\vect{O}_{n-1}-\\vect{T}) & k=n-1\\\\\n",
    "\\vect{W}_{k+1}^T \\vect{\\Delta}_{k+1} & k = n-2,...,-1 \\\\\n",
    "\\end{cases}\\\\\n",
    "\\vect{\\phi}'(\\text{net}_{k}) &= \\vect{O}_k \\circ (\\vect{1}-\\vect{O}_k)  \\text{ for }   k = n-1,...,0 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Update\n",
    "###### Single Input\n",
    "$$\n",
    "\\vect{W}_k := \\vect{W}_k - \\alpha \\diff{E}{\\vect{W}_k}\\\\\n",
    "\\diff{E}{\\vect{W}_k} = \\vect{\\delta}_{k}\n",
    "\\matrix{1 \\\\ \\vect{o}_{k-1}}^T\\ \\text{for } k = n-1,...,0 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Batch Input\n",
    "$$\n",
    "\\vect{W}_k := \\vect{W}_k - \\alpha \\diff{E}{\\vect{W}_k}\\\\\n",
    "\\diff{E}{\\vect{W}_k} = \\frac{1}{m}\\vect{\\Delta}_{k}\n",
    "\\matrix{1 \\\\ \\vect{O}_{k-1}}^T \\text{for } k = n-1,...,0 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where  \n",
    "$\\vect{x}_i$ - the input vector of the  $i$th data point\n",
    "$\\vect{o}_k$ - the output vector of the $k$th layer  \n",
    "$\\vect{\\delta}_k$ - the delta vector of the $k$th layer  \n",
    "$\\vect{W}_k$ - the weight matrix of the $k$th layer  \n",
    "$\\vect{X}$ - the batch input matfix  \n",
    "$\\vect{O}_k$ - the batch output matrix of the $k$th layer  \n",
    "$\\vect{\\Delta}_k$ - the batch delta matrix of the $k$th layer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Defining class for BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(\n",
    "        self,hidden_layer_sizes,\n",
    "        l_rate=.001,\n",
    "        n_epoch=20,\n",
    "        batch_size=20,\n",
    "        random_state=0\n",
    "    ):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.l_rate= float(l_rate)\n",
    "        self.n_epoch = int(n_epoch)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.n = len(hidden_layer_sizes)+1\n",
    "        self.outputs = [None]*(self.n+1)\n",
    "        self.delta = [None]*self.n\n",
    "        \n",
    "        \n",
    "    def activation(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def d_activation(self,x):\n",
    "         return x * (1 - x)\n",
    "    \n",
    "    def pad_ones(X):\n",
    "        pad_width = [(1,0),(0,0)]\n",
    "        return np.pad(X,pad_width=pad_width,constant_values=1)\n",
    "    \n",
    "    def inputs(self,i):\n",
    "        return BPNN.pad_ones(self.outputs[i-1])\n",
    "    \n",
    "    def initialize_random_weights(self):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.weights = [\n",
    "            np.random.standard_normal((o,i+1))*.001\n",
    "            for i,o in zip(\n",
    "                [self.n_inputs]+self.hidden_layer_sizes,\n",
    "                self.hidden_layer_sizes+[self.n_outputs]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def forward_propagate(self, inputs):\n",
    "        assert (self.weights is not None),\"weights not given\"\n",
    "        self.outputs[-1] = inputs\n",
    "        for i in range(self.n):\n",
    "            self.outputs[i] = self.activation(\n",
    "                self.weights[i] @ self.inputs(i)\n",
    "            )\n",
    "        return self.outputs[self.n-1]\n",
    "    \n",
    "    def backward_propagate_error(self, target):\n",
    "        for i in range(self.n-1, -1, -1):\n",
    "            if i == self.n-1:\n",
    "                errors = self.outputs[i] - target\n",
    "            else:\n",
    "                errors = self.weights[i+1][:,1:].T @ self.delta[i+1] \n",
    "            self.delta[i] = errors * self.d_activation(self.outputs[i])\n",
    "\n",
    "    def update_weights(self):\n",
    "        for i in range(self.n):\n",
    "            self.weights[i] -= self.l_rate * self.delta[i] @ self.inputs(i).T/self.batch_size\n",
    "        \n",
    "    def error(self,actual,predicted):\n",
    "        error = actual-predicted\n",
    "        return np.sum(error * error)\n",
    "    \n",
    "    def fit(self, X_train,y_train,verbose=False):\n",
    "        m = X_train.shape[0]\n",
    "        input_matrix = X_train.T\n",
    "        classes = np.unique(y_train)\n",
    "        target_matrix = (y_train.reshape(-1,1) == classes).T\n",
    "        self.n_inputs = input_matrix.shape[0]\n",
    "        self.n_outputs = target_matrix.shape[0]\n",
    "        self.initialize_random_weights()\n",
    "        if verbose:\n",
    "            print(\"Initial Weights:\")\n",
    "            print(*self.weights,sep=\"\\n\")\n",
    "            print(\"Training:\")\n",
    "            \n",
    "        for epoch in range(self.n_epoch):\n",
    "            sum_error = 0\n",
    "            fs = range(m+self.batch_size)\n",
    "            for f,t in zip(fs,fs[1:]):\n",
    "                outputs = self.forward_propagate(input_matrix[:,f:t])\n",
    "                sum_error += self.error(target_matrix[:,f:t],outputs)\n",
    "                self.backward_propagate_error(target_matrix[:,f:t])\n",
    "                self.update_weights()\n",
    "            if verbose:\n",
    "                print(f'> epoch={epoch+1}, lrate={self.l_rate:.3}, error={sum_error/m:.5f}')\n",
    "        if verbose:\n",
    "            print(\"Trained Weights:\")\n",
    "            print(*self.weights,sep=\"\\n\")\n",
    "            \n",
    "    def predict(self, inputs):\n",
    "        outputs = self.forward_propagate(inputs.T).T.argmax(axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def accuracy(self,X_test,y_test):\n",
    "        return (self.predict(X_test)==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Loading and processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"datasets/titanic_processed.csv\")\n",
    "X = titanic_df.drop('Survived',axis = 1).values\n",
    "y = titanic_df['Survived'].values\n",
    "split_ratio = 0.8\n",
    "s = int(split_ratio*X.shape[0])\n",
    "X_train, X_test = X[:s],X[s:]\n",
    "y_train, y_test = y[:s],y[s:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Implementing BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      "[[ 1.33158650e-03  7.15278974e-04 -1.54540029e-03 -8.38384993e-06\n",
      "   6.21335974e-04 -7.20085561e-04  2.65511586e-04  1.08548526e-04\n",
      "   4.29143093e-06 -1.74600211e-04]\n",
      " [ 4.33026190e-04  1.20303737e-03 -9.65065671e-04  1.02827408e-03\n",
      "   2.28630130e-04  4.45137613e-04 -1.13660221e-03  1.35136878e-04\n",
      "   1.48453700e-03 -1.07980489e-03]\n",
      " [-1.97772828e-03 -1.74337230e-03  2.66070164e-04  2.38496733e-03\n",
      "   1.12369125e-03  1.67262221e-03  9.91492158e-05  1.39799638e-03\n",
      "  -2.71247988e-04  6.13204185e-04]\n",
      " [-2.67317189e-04 -5.49309014e-04  1.32708296e-04 -4.76142015e-04\n",
      "   1.30847308e-03  1.95013279e-04  4.00209988e-04 -3.37632337e-04\n",
      "   1.25647226e-03 -7.31969502e-04]\n",
      " [ 6.60231551e-04 -3.50871891e-04 -9.39433360e-04 -4.89337217e-04\n",
      "  -8.04591142e-04 -2.12697639e-04 -3.39140246e-04  3.12169936e-04\n",
      "   5.65152670e-04 -1.47420258e-04]]\n",
      "[[-2.59053368e-05  2.89094204e-04 -5.39879071e-04  7.08160020e-04\n",
      "   8.42224738e-04  2.03580797e-04]\n",
      " [ 2.39470366e-03  9.17458938e-04 -1.12272471e-04 -3.62180447e-04\n",
      "  -2.32182256e-04 -5.01728900e-04]\n",
      " [ 1.12878515e-03 -6.97810030e-04 -8.11221838e-05 -5.29296081e-04\n",
      "   1.04618286e-03 -1.41855603e-03]]\n",
      "[[-0.0003625  -0.00012191  0.00031936  0.0004609 ]\n",
      " [-0.00021579  0.00098907  0.00031475  0.00246765]]\n",
      "Training:\n",
      "> epoch=1, lrate=30.0, error=0.49515\n",
      "> epoch=2, lrate=30.0, error=0.49066\n",
      "> epoch=3, lrate=30.0, error=0.44759\n",
      "> epoch=4, lrate=30.0, error=0.32836\n",
      "> epoch=5, lrate=30.0, error=0.32012\n",
      "> epoch=6, lrate=30.0, error=0.31767\n",
      "> epoch=7, lrate=30.0, error=0.31607\n",
      "> epoch=8, lrate=30.0, error=0.31484\n",
      "> epoch=9, lrate=30.0, error=0.31382\n",
      "> epoch=10, lrate=30.0, error=0.31292\n",
      "> epoch=11, lrate=30.0, error=0.31207\n",
      "> epoch=12, lrate=30.0, error=0.31125\n",
      "> epoch=13, lrate=30.0, error=0.31043\n",
      "> epoch=14, lrate=30.0, error=0.30963\n",
      "> epoch=15, lrate=30.0, error=0.30886\n",
      "> epoch=16, lrate=30.0, error=0.30816\n",
      "> epoch=17, lrate=30.0, error=0.30752\n",
      "> epoch=18, lrate=30.0, error=0.30695\n",
      "> epoch=19, lrate=30.0, error=0.30645\n",
      "> epoch=20, lrate=30.0, error=0.30598\n",
      "Trained Weights:\n",
      "[[ 2.4976328  -3.27137878 -1.35600823  0.52673885  0.52304233 -3.19704645\n",
      "   0.39883285 -0.40978078 -0.51246783 -3.54894486]\n",
      " [ 2.49858236 -3.27054553 -1.35717467  0.52721097  0.5224186  -3.19489909\n",
      "   0.39699621 -0.40938148 -0.51440629 -3.54895058]\n",
      " [ 2.50036793 -3.27256362 -1.36248268  0.52726938  0.51917641 -3.17240322\n",
      "   0.39203713 -0.40863187 -0.52741317 -3.5374918 ]\n",
      " [ 2.49684424 -3.26991156 -1.35703243  0.52480005  0.52215121 -3.1869823\n",
      "   0.39638606 -0.41104905 -0.51872859 -3.54117576]\n",
      " [ 2.49974609 -3.27394878 -1.35582883  0.52807662  0.52134853 -3.19668184\n",
      "   0.39856944 -0.4084107  -0.51188295 -3.55207963]]\n",
      "[[ 0.97395648 -2.1637305  -2.16450945 -2.15728669 -2.15967589 -2.16477422]\n",
      " [ 1.70663229 -2.05598908 -2.05676708 -2.04797014 -2.05198676 -2.05873351]\n",
      " [ 1.40632024 -2.09847304 -2.09768519 -2.09035198 -2.09225785 -2.1003679 ]]\n",
      "[[-2.60724793  1.55437491  1.68003918  1.61398662]\n",
      " [ 2.60724975 -1.55498627 -1.68088901 -1.61254007]]\n",
      "Evaluation:\n",
      "Acuracy of the classifier: 85.96%\n"
     ]
    }
   ],
   "source": [
    "b = BPNN(\n",
    "    hidden_layer_sizes = [5,3],\n",
    "    l_rate=30, n_epoch=20, batch_size=25,random_state=10\n",
    ")\n",
    "b.fit(X_train,y_train,verbose=True)\n",
    "print(\"Evaluation:\")\n",
    "print(f\"Acuracy of the classifier: {b.accuracy(X_test,y_test)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program 1 - Implementing SVM from scratch using CVXOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIM\n",
    "To implement SVM from scratch using CVXOPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula\n",
    "##### SVM statement in dual form\n",
    "$$\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{\\mathbf{#1}}}\n",
    "\\begin{aligned}\n",
    "    & \\min_{\\vect{\\alpha}}  \\frac{1}{2}  \\vect{\\alpha}^T  \\left( \\vect{y}\\vect{y}^T \\circ (\\Phi(\\vect{X})\\Phi(\\vect{X})^T \\right)  \\vect{\\alpha} - \\vect{1}^T \\vect{\\alpha}\\\\\n",
    "s.t.&  - \\alpha_i \\leq 0 \\\\\n",
    "    & \\alpha_i \\leq C\\\\\n",
    "    & y^T \\vect{\\alpha} = 0  \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard form of a quadratic program\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\min_{\\vect{x}}  \\frac{1}{2}  \\vect{x}^T  \\vect{P}  \\vect{x} - \\vect{q}^T\\vect{x}\\\\\n",
    "s.t.&  \\vect{G}\\vect{x} \\leq \\vect{h} \\\\\n",
    "    & A \\vect{x} = \\vect{b} \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Formulization\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\vect{P}&= \\vect{y}\\vect{y}^T \\circ \\Phi(\\vect{X})\\Phi(\\vect{X})^T\n",
    "& \\vect{q}&= - \\vect{1}_n\\\\\n",
    "\\vect{G}&= \\begin{bmatrix}\n",
    "    \\vect{-I}_n\\\\\n",
    "    \\vect{I}_n\n",
    "\\end{bmatrix} \n",
    "& \\vect{h}&=\\begin{bmatrix}\n",
    "    C \\cdot \\vect{1}_n^T\\\\\n",
    "    \\vect{0}_n^T\n",
    "\\end{bmatrix}\\\\\n",
    "\\vect{A} &= [\\vect{y}] \n",
    "&\\vect{b} &= [0]\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Rule\n",
    "$$\n",
    "\\vect{\\hat y} = \\mathrm{sign}\\left( (\\vect{\\alpha}^T \\circ \\vect{y}^T) \\Phi(\\vect{X})\\Phi(\\vect{X})^T  + b \\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Defining class for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from cvxopt import solvers\n",
    "from cvxopt import matrix\n",
    "\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C,kernel):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def fit(self,X_train,y_train):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X = self.scaler.fit_transform(X_train)\n",
    "        self.y = y_train.reshape(-1,1)\n",
    "        \n",
    "        n=self.X.shape[0]\n",
    "        I_n = np.eye(n)\n",
    "        P=(self.y@self.y.T)*self.kernel(self.X,self.X)\n",
    "        q=np.full(n,-1)\n",
    "        G=np.vstack((I_n,-1*I_n))\n",
    "        h=np.hstack((np.full(n,self.C),np.zeros(n)))\n",
    "        A=y_train.reshape(1,-1)\n",
    "        b=np.zeros(1)\n",
    "\n",
    "        P,q,G,h,A,b = map(lambda x : matrix(x,tc=\"d\"),(P,q,G,h,A,b))\n",
    "\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "        self.a = np.asarray(solution['x']).squeeze()\n",
    "        \n",
    "        support_indices = np.logical_and(self.a>=1e-10, self.a<self.C)\n",
    "        X_S = self.X[support_indices]\n",
    "        self.b = np.mean(self.y - self.a*self.y.T @ self.kernel(self.X, X_S))\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        X_test=self.scaler.transform(X_test)\n",
    "        return np.sign(self.a*self.y.T @ self.kernel(self.X, X_test) + self.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Defining Radial Basis Function(RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X1,X2,sigma):\n",
    "    return np.exp(-cdist(X1, X2, 'sqeuclidean') / (2*sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Loading and Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('datasets/titanic_processed.csv')\n",
    "X = titanic_df.drop('Survived',axis = 1).values\n",
    "y = titanic_df['Survived'].values\n",
    "y[y==0] = -1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Implementing SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1166e+02 -5.8558e+02  6e+03  8e+00  3e-15\n",
      " 1: -8.8848e+01 -4.9225e+02  6e+02  4e-01  3e-15\n",
      " 2: -8.4608e+01 -1.3669e+02  5e+01  2e-03  2e-15\n",
      " 3: -9.2566e+01 -1.1007e+02  2e+01  5e-04  2e-15\n",
      " 4: -9.5567e+01 -1.0239e+02  7e+00  1e-04  2e-15\n",
      " 5: -9.6721e+01 -9.9922e+01  3e+00  6e-05  2e-15\n",
      " 6: -9.7365e+01 -9.8738e+01  1e+00  8e-06  2e-15\n",
      " 7: -9.7606e+01 -9.8266e+01  7e-01  2e-06  2e-15\n",
      " 8: -9.7781e+01 -9.7964e+01  2e-01  2e-07  2e-15\n",
      " 9: -9.7826e+01 -9.7894e+01  7e-02  4e-08  2e-15\n",
      "10: -9.7850e+01 -9.7861e+01  1e-02  5e-09  2e-15\n",
      "11: -9.7852e+01 -9.7857e+01  4e-03  7e-10  2e-15\n",
      "12: -9.7854e+01 -9.7855e+01  1e-03  1e-10  2e-15\n",
      "13: -9.7854e+01 -9.7855e+01  2e-04  2e-11  2e-15\n",
      "14: -9.7854e+01 -9.7854e+01  4e-05  3e-12  2e-15\n",
      "Optimal solution found.\n",
      "Accuracy of the classifer: 75.28%\n"
     ]
    }
   ],
   "source": [
    "from functools import partial \n",
    "C = .35\n",
    "sigma = 2.5\n",
    "kernel = partial(rbf_kernel,sigma=sigma)\n",
    "\n",
    "svm_classifier = SVM(C,kernel)\n",
    "svm_classifier.fit(X_train,y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "print(f'Accuracy of the classifer: {(y_test == y_pred).mean()*100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7023248c40563a766f3ae9a0fc81476c1e46277ee22e162240a9cb41b674a272"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
